{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/VXNGDfOraaDcADnGzYKl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaunak-badani/Duke-Fall-24-Assignments/blob/main/520_Modeling_Processes_and_Algorithms/snippets/Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings in Pytorch are just a mapping from words to vectors.\n",
        "Usually the weight matrix is of size (VOCAB_SIZE, EMBEDDING_DIMS).\n",
        "\n",
        "You pass in indices of the words for which you want the embeddings, and the output is an embedding.\n",
        "\n",
        "W -> (VOCAB_SIZE, EMBEDDING_DIM)\n",
        "\n",
        "If you pass in the tensor [[0, 1]] to it, it just returns the corresponding row vectors of W.\n",
        "\n",
        "W[0, 1] is the output"
      ],
      "metadata": {
        "id": "NziCFRquqCKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the vocabulary and create word-to-index mapping\n",
        "vocab = [\"hello\", \"world\", \"good\", \"day\", \"bad\", \"happy\", \"sad\", \"<PAD>\"]\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "# Define the model\n",
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(SimpleClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=word_to_idx[\"<PAD>\"])\n",
        "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        pooled = torch.mean(embedded, dim=1)\n",
        "        hidden = self.relu(self.fc1(pooled))\n",
        "        output = self.fc2(hidden)\n",
        "        return output\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 50\n",
        "hidden_dim = 20\n",
        "output_dim = 2\n",
        "model = SimpleClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "qw8xjuQhwuxe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare some dummy training data\n",
        "sentences = [\n",
        "    [\"hello\", \"world\"],\n",
        "    [\"good\", \"day\"],\n",
        "    [\"sad\", \"world\"],\n",
        "    [\"bad\", \"day\"]\n",
        "]\n",
        "labels = torch.tensor([0, 1, 0, 1])\n",
        "\n",
        "# Convert sentences to indices\n",
        "indexed_sentences = [[word_to_idx[word] for word in sentence] for sentence in sentences]\n",
        "max_len = max(len(sentence) for sentence in indexed_sentences)\n",
        "padded_sentences = [sentence + [word_to_idx[\"<PAD>\"]] * (max_len - len(sentence)) for sentence in indexed_sentences]\n",
        "input_tensor = torch.tensor(padded_sentences)"
      ],
      "metadata": {
        "id": "Xmy6lNhvotm0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euQrMlKEq__Q",
        "outputId": "7029ab56-4351-437f-b81c-a8a1528b2060"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [2, 3],\n",
              "        [6, 1],\n",
              "        [4, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding(torch.tensor([0, 1], dtype = torch.long).view(1, -1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hogunGBLouEZ",
        "outputId": "ad738b93-b213-4b68-d1af-883df4b5f433"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 8.5968e-01,  1.1785e+00, -7.8363e-01,  4.0976e-01,  1.4115e+00,\n",
              "           1.7898e+00, -1.4364e+00, -1.2868e+00,  1.1944e+00, -5.4213e-01,\n",
              "          -6.0180e-01,  8.7879e-01,  1.4892e+00, -4.6131e-01, -1.6923e+00,\n",
              "          -7.8046e-01, -5.9111e-01,  7.4712e-01,  2.0151e+00, -1.4224e+00,\n",
              "           2.9555e+00,  3.2424e-01, -3.5774e-01, -9.1922e-01, -4.2938e-01,\n",
              "           1.7404e-01, -8.3192e-01,  1.5080e-03, -8.3295e-01,  1.0297e+00,\n",
              "          -4.2784e-01, -8.9101e-01,  1.1736e+00, -8.4671e-01, -1.2132e+00,\n",
              "          -8.9476e-01,  7.9593e-01,  3.1484e-01, -5.8347e-01, -3.5326e-01,\n",
              "          -1.8668e-01,  1.9908e-01, -2.2509e-01, -3.6270e-01, -7.9253e-01,\n",
              "           2.6316e-01,  9.8670e-01,  8.5062e-01, -1.2813e+00,  4.2514e-01],\n",
              "         [ 1.1730e+00,  3.0943e-01, -9.0146e-01, -1.0058e+00, -1.4448e+00,\n",
              "          -1.1262e+00,  1.8576e-01, -1.1980e+00,  5.9337e-01, -1.5322e-01,\n",
              "          -1.3244e+00, -8.1402e-02, -9.6001e-01, -2.1825e+00, -2.5827e-01,\n",
              "           4.0446e-01,  2.2148e-01, -3.4101e-03,  5.3017e-01, -1.5036e-01,\n",
              "          -2.4751e-01, -7.1154e-01, -4.5041e-01,  3.2172e-01, -4.7106e-02,\n",
              "           9.9015e-01,  2.5758e-01,  1.9925e-01, -1.2047e+00, -2.6215e+00,\n",
              "          -4.8740e-01,  1.1292e+00,  4.9225e-01, -4.4986e-01,  1.0877e-01,\n",
              "           1.3774e+00, -7.4402e-01, -6.4350e-01,  7.3243e-02,  1.0581e+00,\n",
              "          -2.5132e-01, -8.8588e-01,  1.0318e+00,  3.2854e-01, -3.0107e+00,\n",
              "          -1.2484e+00,  3.3041e-01,  3.3599e-01,  5.0290e-02,  1.4234e+00]]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight[[0, 1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIRvqE-9rWRH",
        "outputId": "795b571e-27d0-4f95-9d19-8c5280fbbb75"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8.5968e-01,  1.1785e+00, -7.8363e-01,  4.0976e-01,  1.4115e+00,\n",
              "          1.7898e+00, -1.4364e+00, -1.2868e+00,  1.1944e+00, -5.4213e-01,\n",
              "         -6.0180e-01,  8.7879e-01,  1.4892e+00, -4.6131e-01, -1.6923e+00,\n",
              "         -7.8046e-01, -5.9111e-01,  7.4712e-01,  2.0151e+00, -1.4224e+00,\n",
              "          2.9555e+00,  3.2424e-01, -3.5774e-01, -9.1922e-01, -4.2938e-01,\n",
              "          1.7404e-01, -8.3192e-01,  1.5080e-03, -8.3295e-01,  1.0297e+00,\n",
              "         -4.2784e-01, -8.9101e-01,  1.1736e+00, -8.4671e-01, -1.2132e+00,\n",
              "         -8.9476e-01,  7.9593e-01,  3.1484e-01, -5.8347e-01, -3.5326e-01,\n",
              "         -1.8668e-01,  1.9908e-01, -2.2509e-01, -3.6270e-01, -7.9253e-01,\n",
              "          2.6316e-01,  9.8670e-01,  8.5062e-01, -1.2813e+00,  4.2514e-01],\n",
              "        [ 1.1730e+00,  3.0943e-01, -9.0146e-01, -1.0058e+00, -1.4448e+00,\n",
              "         -1.1262e+00,  1.8576e-01, -1.1980e+00,  5.9337e-01, -1.5322e-01,\n",
              "         -1.3244e+00, -8.1402e-02, -9.6001e-01, -2.1825e+00, -2.5827e-01,\n",
              "          4.0446e-01,  2.2148e-01, -3.4101e-03,  5.3017e-01, -1.5036e-01,\n",
              "         -2.4751e-01, -7.1154e-01, -4.5041e-01,  3.2172e-01, -4.7106e-02,\n",
              "          9.9015e-01,  2.5758e-01,  1.9925e-01, -1.2047e+00, -2.6215e+00,\n",
              "         -4.8740e-01,  1.1292e+00,  4.9225e-01, -4.4986e-01,  1.0877e-01,\n",
              "          1.3774e+00, -7.4402e-01, -6.4350e-01,  7.3243e-02,  1.0581e+00,\n",
              "         -2.5132e-01, -8.8588e-01,  1.0318e+00,  3.2854e-01, -3.0107e+00,\n",
              "         -1.2484e+00,  3.3041e-01,  3.3599e-01,  5.0290e-02,  1.4234e+00]],\n",
              "       grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0_B5h2-n6if",
        "outputId": "82bbc40b-d811-476a-ba23-84623e407fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.5055\n",
            "Epoch [20/100], Loss: 0.3706\n",
            "Epoch [30/100], Loss: 0.2468\n",
            "Epoch [40/100], Loss: 0.1540\n",
            "Epoch [50/100], Loss: 0.0949\n",
            "Epoch [60/100], Loss: 0.0595\n",
            "Epoch [70/100], Loss: 0.0392\n",
            "Epoch [80/100], Loss: 0.0275\n",
            "Epoch [90/100], Loss: 0.0204\n",
            "Epoch [100/100], Loss: 0.0159\n",
            "Predicted class for 'happy world': 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(input_tensor)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Test the model\n",
        "test_sentence = [\"happy\", \"world\"]\n",
        "test_indexed = [word_to_idx[word] for word in test_sentence]\n",
        "test_padded = test_indexed + [word_to_idx[\"<PAD>\"]] * (max_len - len(test_indexed))\n",
        "test_tensor = torch.tensor([test_padded])\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(test_tensor)\n",
        "    predicted = torch.argmax(output, dim=1)\n",
        "    print(f\"Predicted class for 'happy world': {predicted.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcAf10qxn8rT",
        "outputId": "09ab956c-92c3-49ea-d20d-be4811a1949f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = nn.Embedding(5, 3)\n",
        "\n",
        "i_tensor = torch.tensor([[1, 2]], dtype = torch.long).view(1, -1)\n",
        "h = k(i_tensor)\n",
        "l = h.sum()"
      ],
      "metadata": {
        "id": "F8yqvmlioZDq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l.backward()"
      ],
      "metadata": {
        "id": "JV0quC33yvKl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.weight.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhWZhSpHyvxX",
        "outputId": "66528752-5e1a-4817-f7c7-0768b081d5bd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}